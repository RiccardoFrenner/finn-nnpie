{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Callable, Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchdiffeq import odeint\n",
    "\n",
    "\n",
    "class AnalyticRetardation:\n",
    "    @staticmethod\n",
    "    def linear(u, por, rho_s, Kd):\n",
    "        factor = 1 + (1 - por) / por * rho_s * Kd\n",
    "        ones_like_u = u * 0 + 1\n",
    "        return ones_like_u * factor\n",
    "\n",
    "    @staticmethod\n",
    "    def freundlich(u, por, rho_s, Kf, nf):\n",
    "        return 1 + (1 - por) / por * rho_s * Kf * nf * (u + 1e-6) ** (nf - 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def langmuir(u, por, rho_s, smax, Kl):\n",
    "        return 1 + (1 - por) / por * rho_s * smax * Kl / ((u + Kl) ** 2)\n",
    "\n",
    "\n",
    "def create_mlp(layers: list[int], activation_fun, activation_fun_end, dropout: int = 0):\n",
    "    network_layers = []\n",
    "\n",
    "    for i in range(len(layers) - 1):\n",
    "        network_layers.append(nn.Linear(layers[i], layers[i + 1]))\n",
    "        if i < len(layers) - 2:\n",
    "            network_layers.append(activation_fun)\n",
    "            if dropout > 0:\n",
    "                print(\"Adding dropout\")\n",
    "                network_layers.append(nn.Dropout(p=dropout / 100.0))\n",
    "\n",
    "    network_layers.append(activation_fun_end)\n",
    "\n",
    "    return nn.Sequential(*network_layers)\n",
    "\n",
    "\n",
    "class Flux_Kernels(nn.Module):\n",
    "    def __init__(self, u0, cfg, var_idx, ret_inv_fun=None):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        Inputs:\n",
    "            u0      : initial condition, dim: [Nx, Ny]\n",
    "            cfg     : configuration object of the model setup, containing boundary\n",
    "                        condition types, values, learnable parameter settings, etc.\n",
    "            var_idx : index of the calculated variable (could be > 1 for coupled\n",
    "                        systems)\n",
    "        \"\"\"\n",
    "\n",
    "        super(Flux_Kernels, self).__init__()\n",
    "\n",
    "        self.Nx = u0.size(0)\n",
    "        self.Ny = u0.size(1)\n",
    "        self.u0 = u0\n",
    "\n",
    "        # Variables that act as switch to use different types of boundary\n",
    "        # condition\n",
    "        # Each variable consists of boolean values at all 2D domain boundaries:\n",
    "        # [left (x = 0), right (x = Nx), top (y = 0), bottom (y = Ny)]\n",
    "        # For 1D, only the first two values matter, set the last two values to\n",
    "        # be no-flux boundaries (zero neumann_val)\n",
    "        self.dirichlet_bool = cfg.dirichlet_bool[var_idx]\n",
    "        self.neumann_bool = cfg.neumann_bool[var_idx]\n",
    "        self.cauchy_bool = cfg.cauchy_bool[var_idx]\n",
    "\n",
    "        # Variables that store the values of the boundary condition of each type\n",
    "        # Values = 0 if not used, otherwise specify in the configuration file\n",
    "        # Each variable consists of real values at all 2D domain boundaries:\n",
    "        # [left (x = 0), right (x = Nx), top (y = 0), bottom (y = Ny)]\n",
    "        # For 1D, only the first two values matter, set the last two values to\n",
    "        # be no-flux boundaries\n",
    "        if torch.is_tensor(cfg.dirichlet_val[var_idx]):\n",
    "            self.dirichlet_val = cfg.dirichlet_val[var_idx]\n",
    "        else:\n",
    "            self.dirichlet_val = torch.tensor(cfg.dirichlet_val[var_idx])\n",
    "\n",
    "        if torch.is_tensor(cfg.neumann_val[var_idx]):\n",
    "            self.neumann_val = cfg.neumann_val[var_idx]\n",
    "        else:\n",
    "            self.neumann_val = torch.tensor(cfg.neumann_val[var_idx])\n",
    "\n",
    "        # For Cauchy BC, the initial Cauchy value is set to be the initial\n",
    "        # condition at each corresponding domain boundary, and will be updated\n",
    "        # through time\n",
    "        self.cauchy_val = []\n",
    "        self.cauchy_val.append(u0[0, :])\n",
    "        self.cauchy_val.append(u0[-1, :])\n",
    "        self.cauchy_val.append(u0[:, 0])\n",
    "        self.cauchy_val.append(u0[:, -1])\n",
    "\n",
    "        # Set the Cauchy BC multiplier (to be multiplied with the gradient of\n",
    "        # the unknown variable and the diffusion coefficient)\n",
    "        if torch.is_tensor(cfg.cauchy_mult[var_idx]):\n",
    "            self.cauchy_mult = cfg.cauchy_mult[var_idx]\n",
    "        else:\n",
    "            self.cauchy_mult = torch.tensor(cfg.cauchy_mult[var_idx])\n",
    "\n",
    "        # If numerical stencil is to be learned, initialize to +1 and -1 with\n",
    "        # a standard deviation of 0.1 each, otherwise set it to fixed values\n",
    "        self.learn_stencil = cfg.learn_stencil[var_idx]\n",
    "        if self.learn_stencil:\n",
    "            self.stencil = torch.tensor(\n",
    "                [\n",
    "                    torch.normal(torch.tensor([1.0]), torch.tensor([0.1])),\n",
    "                    torch.normal(torch.tensor([-1.0]), torch.tensor([0.1])),\n",
    "                ],\n",
    "                dtype=torch.float,\n",
    "            )\n",
    "            self.stencil = nn.Parameter(self.stencil)\n",
    "        else:\n",
    "            self.stencil = torch.tensor([1.0, -1.0])\n",
    "\n",
    "        if torch.is_tensor(cfg.D_eff[var_idx]):\n",
    "            self.D_eff = cfg.D_eff[var_idx]\n",
    "        else:\n",
    "            self.D_eff = torch.tensor(cfg.D_eff[var_idx])\n",
    "        if cfg.learn_coeff[var_idx]:\n",
    "            self.D_eff = nn.Parameter(torch.tensor([self.D_eff], dtype=torch.float))\n",
    "\n",
    "        self.is_retardation_a_func = cfg.is_retardation_a_func[var_idx]\n",
    "\n",
    "        # Extract value of the normalizing constant to be applied to the output\n",
    "        # of the NN that predicts the diffusion coefficient function\n",
    "        self.p_exp = torch.tensor(cfg.p_exp_flux[var_idx])\n",
    "\n",
    "        # Initialize a NN to predict retardation factor as a function of\n",
    "        # the unknown variable if necessary\n",
    "        if ret_inv_fun is not None:\n",
    "            self.ret_inv_fun = ret_inv_fun\n",
    "            self.p_exp = nn.Parameter(torch.tensor([self.p_exp], dtype=torch.float))\n",
    "\n",
    "    def forward(self, u_main, u_coupled, t):\n",
    "        if u_coupled.shape[0] != 1:\n",
    "            u_coupled = u_coupled.unsqueeze(0)\n",
    "        u_coupled = u_coupled.permute(1, 2, 0)\n",
    "\n",
    "        # Calculate the flux multiplier (retardation function) if set\n",
    "        # to be a function, otherwise set as tensor of ones\n",
    "        if self.is_retardation_a_func:\n",
    "            ret_inv = self.ret_inv_fun(u_coupled).squeeze(2) * 10**self.p_exp\n",
    "        else:\n",
    "            ret_inv = torch.ones(self.Nx, self.Ny)\n",
    "\n",
    "        # Squeeze the u_main dimension into [Nx, Ny]\n",
    "        u_main = u_main.squeeze(0)\n",
    "\n",
    "        # Left Boundary Condition\n",
    "        if self.dirichlet_bool[0]:\n",
    "            # If Dirichlet, calculate the flux at the boundary using the\n",
    "            # Dirichlet value as a constant\n",
    "            left_bound_flux = (\n",
    "                (\n",
    "                    self.stencil[0] * self.dirichlet_val[0]\n",
    "                    + self.stencil[1] * u_main[0, :]\n",
    "                ).unsqueeze(0)\n",
    "                * self.D_eff\n",
    "                * ret_inv[0, :]\n",
    "            )\n",
    "\n",
    "        elif self.neumann_bool[0]:\n",
    "            # If Neumann, set the Neumann value as the flux at the boundary\n",
    "            left_bound_flux = torch.cat(\n",
    "                self.Ny * [self.neumann_val[0].unsqueeze(0)]\n",
    "            ).unsqueeze(0)\n",
    "\n",
    "        elif self.cauchy_bool[0]:\n",
    "            # If Cauchy, first set the value to be equal to the initial condition\n",
    "            # at t = 0.0, otherwise update the value according to the previous\n",
    "            # time step value\n",
    "            if t == 0.0:\n",
    "                self.cauchy_val[0] = self.u0[0, :]\n",
    "            else:\n",
    "                self.cauchy_val[0] = (\n",
    "                    (u_main[0, :] - self.cauchy_val[0]) * self.cauchy_mult * self.D_eff\n",
    "                )\n",
    "            # Calculate the flux at the boundary using the updated Cauchy value\n",
    "            left_bound_flux = (\n",
    "                (\n",
    "                    self.stencil[0] * self.cauchy_val[0]\n",
    "                    + self.stencil[1] * u_main[0, :]\n",
    "                ).unsqueeze(0)\n",
    "                * self.D_eff\n",
    "                * ret_inv[0, :]\n",
    "            )\n",
    "\n",
    "        # Calculate the fluxes of each control volume with its left neighboring cell\n",
    "        left_neighbors = (\n",
    "            (self.stencil[0] * u_main[:-1, :] + self.stencil[1] * u_main[1:, :])\n",
    "            * self.D_eff\n",
    "            * ret_inv[1:, :]\n",
    "        )\n",
    "        # Concatenate the left boundary fluxes with the left neighbors fluxes\n",
    "        left_flux = torch.cat((left_bound_flux, left_neighbors))\n",
    "\n",
    "        # Right Boundary Condition\n",
    "        if self.dirichlet_bool[1]:\n",
    "            # If Dirichlet, calculate the flux at the boundary using the\n",
    "            # Dirichlet value as a constant\n",
    "            right_bound_flux = (\n",
    "                (\n",
    "                    self.stencil[0] * self.dirichlet_val[1]\n",
    "                    + self.stencil[1] * u_main[-1, :]\n",
    "                ).unsqueeze(0)\n",
    "                * self.D_eff\n",
    "                * ret_inv[-1, :]\n",
    "            )\n",
    "\n",
    "        elif self.neumann_bool[1]:\n",
    "            # If Neumann, set the Neumann value as the flux at the boundary\n",
    "            right_bound_flux = torch.cat(\n",
    "                self.Ny * [self.neumann_val[1].unsqueeze(0)]\n",
    "            ).unsqueeze(0)\n",
    "\n",
    "        elif self.cauchy_bool[1]:\n",
    "            # If Cauchy, first set the value to be equal to the initial condition\n",
    "            # at t = 0.0, otherwise update the value according to the previous\n",
    "            # time step value\n",
    "            if t == 0.0:\n",
    "                self.cauchy_val[1] = self.u0[-1, :]\n",
    "            else:\n",
    "                self.cauchy_val[1] = (\n",
    "                    (u_main[-1, :] - self.cauchy_val[1]) * self.cauchy_mult * self.D_eff\n",
    "                )\n",
    "            # Calculate the flux at the boundary using the updated Cauchy value\n",
    "            right_bound_flux = (\n",
    "                (\n",
    "                    self.stencil[0] * self.cauchy_val[1]\n",
    "                    + self.stencil[1] * u_main[-1, :]\n",
    "                ).unsqueeze(0)\n",
    "                * self.D_eff\n",
    "                * ret_inv[-1, :]\n",
    "            )\n",
    "\n",
    "        # Calculate the fluxes of each control volume with its right neighboring cell\n",
    "        right_neighbors = (\n",
    "            (self.stencil[0] * u_main[1:, :] + self.stencil[1] * u_main[:-1, :])\n",
    "            * self.D_eff\n",
    "            * ret_inv[:-1, :]\n",
    "        )\n",
    "        # Concatenate the right neighbors fluxes with the right boundary fluxes\n",
    "        right_flux = torch.cat((right_neighbors, right_bound_flux))\n",
    "\n",
    "        # Top Boundary Condition\n",
    "        if self.dirichlet_bool[2]:\n",
    "            # If Dirichlet, calculate the flux at the boundary using the\n",
    "            # Dirichlet value as a constant\n",
    "            top_bound_flux = (\n",
    "                (\n",
    "                    self.stencil[0] * self.dirichlet_val[2]\n",
    "                    + self.stencil[1] * u_main[:, 0]\n",
    "                ).unsqueeze(1)\n",
    "                * self.D_eff\n",
    "                * ret_inv[:, 0]\n",
    "            )\n",
    "\n",
    "        elif self.neumann_bool[2]:\n",
    "            # If Neumann, set the Neumann value as the flux at the boundary\n",
    "            top_bound_flux = torch.cat(\n",
    "                self.Nx * [self.neumann_val[2].unsqueeze(0)]\n",
    "            ).unsqueeze(1)\n",
    "\n",
    "        elif self.cauchy_bool[2]:\n",
    "            # If Cauchy, first set the value to be equal to the initial condition\n",
    "            # at t = 0.0, otherwise update the value according to the previous\n",
    "            # time step value\n",
    "            if t == 0.0:\n",
    "                self.cauchy_val[2] = self.u0[:, 0]\n",
    "            else:\n",
    "                self.cauchy_val[2] = (\n",
    "                    (u_main[:, 0] - self.cauchy_val[2]) * self.cauchy_mult * self.D_eff\n",
    "                )\n",
    "            # Calculate the flux at the boundary using the updated Cauchy value\n",
    "            top_bound_flux = (\n",
    "                (\n",
    "                    self.stencil[0] * self.cauchy_val[2]\n",
    "                    + self.stencil[1] * u_main[:, 0]\n",
    "                ).unsqueeze(1)\n",
    "                * self.D_eff\n",
    "                * ret_inv[:, 0]\n",
    "            )\n",
    "\n",
    "        # Calculate the fluxes of each control volume with its top neighboring cell\n",
    "        top_neighbors = (\n",
    "            (self.stencil[0] * u_main[:, :-1] + self.stencil[1] * u_main[:, 1:])\n",
    "            * self.D_eff\n",
    "            * ret_inv[:, 1:]\n",
    "        )\n",
    "        # Concatenate the top boundary fluxes with the top neighbors fluxes\n",
    "        top_flux = torch.cat((top_bound_flux, top_neighbors), dim=1)\n",
    "\n",
    "        # Bottom Boundary Condition\n",
    "        if self.dirichlet_bool[3]:\n",
    "            # If Dirichlet, calculate the flux at the boundary using the\n",
    "            # Dirichlet value as a constant\n",
    "            bottom_bound_flux = (\n",
    "                (\n",
    "                    self.stencil[0] * self.dirichlet_val[3]\n",
    "                    + self.stencil[1] * u_main[:, -1]\n",
    "                ).unsqueeze(1)\n",
    "                * self.D_eff\n",
    "                * ret_inv[:, -1]\n",
    "            )\n",
    "\n",
    "        elif self.neumann_bool[3]:\n",
    "            # If Neumann, set the Neumann value as the flux at the boundary\n",
    "            bottom_bound_flux = torch.cat(\n",
    "                self.Nx * [self.neumann_val[3].unsqueeze(0)]\n",
    "            ).unsqueeze(1)\n",
    "\n",
    "        elif self.cauchy_bool[3]:\n",
    "            # If Cauchy, first set the value to be equal to the initial condition\n",
    "            # at t = 0.0, otherwise update the value according to the previous\n",
    "            # time step value\n",
    "            if t == 0.0:\n",
    "                self.cauchy_val[3] = self.u0[:, -1]\n",
    "            else:\n",
    "                self.cauchy_val[3] = (\n",
    "                    (u_main[:, -1] - self.cauchy_val[3]) * self.cauchy_mult * self.D_eff\n",
    "                )\n",
    "            # Calculate the flux at the boundary using the updated Cauchy value\n",
    "            bottom_bound_flux = (\n",
    "                (\n",
    "                    self.stencil[0] * self.cauchy_val[3]\n",
    "                    + self.stencil[1] * u_main[:, -1]\n",
    "                ).unsqueeze(1)\n",
    "                * self.D_eff\n",
    "                * ret_inv[:, -1]\n",
    "            )\n",
    "\n",
    "        # Calculate the fluxes of each control volume with its bottom neighboring cell\n",
    "        bottom_neighbors = (\n",
    "            (self.stencil[0] * u_main[:, 1:] + self.stencil[1] * u_main[:, :-1])\n",
    "            * self.D_eff\n",
    "            * ret_inv[:, :-1]\n",
    "        )\n",
    "        # Concatenate the bottom neighbors fluxes with the bottom boundary fluxes\n",
    "        bottom_flux = torch.cat((bottom_neighbors, bottom_bound_flux), dim=1)\n",
    "\n",
    "        # Integrate all fluxes at all control volume boundaries\n",
    "        flux = left_flux + right_flux + top_flux + bottom_flux\n",
    "\n",
    "        return flux\n",
    "\n",
    "\n",
    "class ConcentrationPredictor(nn.Module):\n",
    "    def __init__(self, u0: torch.Tensor, cfg, ret_inv_funs=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            u0 (tensor): initial condition, dim: [num_features, Nx]\n",
    "            cfg (_type_): _description_\n",
    "        \"\"\"\n",
    "        super(ConcentrationPredictor, self).__init__()\n",
    "        if ret_inv_funs is None:\n",
    "            ret_inv_funs = [None] * len(u0)\n",
    "\n",
    "        self.cfg = cfg\n",
    "        self.u0 = u0\n",
    "        self.dudt_fun = ConcentrationChangeRatePredictor(\n",
    "            u0, cfg, ret_inv_funs=ret_inv_funs\n",
    "        )\n",
    "\n",
    "    def forward(self, t):\n",
    "        \"\"\"Predict the concentration profile at given time steps from an initial condition using the FINN method.\n",
    "\n",
    "        Args:\n",
    "            t (tensor): time steps\n",
    "\n",
    "        Returns:\n",
    "            tensor: Full field solution of concentration at given time steps.\n",
    "        \"\"\"\n",
    "\n",
    "        return odeint(self.dudt_fun, self.u0, t, rtol=1e-5, atol=1e-6, method=\"dopri8\")\n",
    "        # return odeint(self.dudt_fun, self.u0, t, rtol=1e-5, atol=1e-6)\n",
    "\n",
    "    def run_training(\n",
    "        self,\n",
    "        t: torch.Tensor,\n",
    "        u_train: torch.Tensor,\n",
    "        out_dir: Path,\n",
    "        max_epochs: int = 100,\n",
    "    ):\n",
    "        \"\"\"Train to predict the concentration from the given full field training data.\n",
    "\n",
    "        Args:\n",
    "\n",
    "            t (tensor): time steps for integration, dim: [Nt,]\n",
    "            x_train (tensor): full field solution at each time step, dim: [Nt, num_features, Nx]\n",
    "        \"\"\"\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        optimizer = torch.optim.LBFGS(self.parameters(), lr=0.1)\n",
    "\n",
    "        u_ret = torch.linspace(0.0, 2.0, 100).view(-1, 1)\n",
    "        ret_linear = AnalyticRetardation.linear(\n",
    "            u_ret, por=self.cfg.por, rho_s=self.cfg.rho_s, Kd=self.cfg.Kd\n",
    "        )\n",
    "        ret_freundlich = AnalyticRetardation.freundlich(\n",
    "            u_ret,\n",
    "            por=self.cfg.por,\n",
    "            rho_s=self.cfg.rho_s,\n",
    "            Kf=self.cfg.Kf,\n",
    "            nf=self.cfg.nf,\n",
    "        )\n",
    "        ret_langmuir = AnalyticRetardation.langmuir(\n",
    "            u_ret,\n",
    "            por=self.cfg.por,\n",
    "            rho_s=self.cfg.rho_s,\n",
    "            smax=self.cfg.smax,\n",
    "            Kl=self.cfg.Kl,\n",
    "        )\n",
    "        np.save(out_dir / \"u_ret.npy\", u_ret)\n",
    "        np.save(out_dir / \"retardation_linear.npy\", ret_linear)\n",
    "        np.save(out_dir / \"retardation_freundlich.npy\", ret_freundlich)\n",
    "        np.save(out_dir / \"retardation_langmuir.npy\", ret_langmuir)\n",
    "        np.save(out_dir / \"c_train.npy\", u_train.numpy())\n",
    "        np.save(out_dir / \"t_train.npy\", t.numpy())\n",
    "\n",
    "        # Define the closure function that consists of resetting the\n",
    "        # gradient buffer, loss function calculation, and backpropagation\n",
    "        # The closure function is necessary for LBFGS optimizer, because\n",
    "        # it requires multiple function evaluations\n",
    "        # The closure function returns the loss value\n",
    "        epoch = 0\n",
    "        # self.por * self.A / self.Q * self.dx\n",
    "        def closure():\n",
    "            self.train()\n",
    "            optimizer.zero_grad()\n",
    "            ode_pred = self.forward(t)  # aka. y_pred\n",
    "            ode_pred_btc = ode_pred[:, 0, -1, 0]\n",
    "            # cauchy_mult = self.dudt_fun.flux_modules[0].cauchy_mult * self.dudt_fun.flux_modules[0].D_eff\n",
    "            # ode_pred_btc = cauchy_mult * (ode_pred[:, 0, -2] - ode_pred[:, 0, -1]).squeeze()\n",
    "            loss = self.cfg.error_mult * torch.mean((u_train - ode_pred_btc) ** 2)\n",
    "            print(f\"{u_train.shape=}\")\n",
    "            print(f\"{ode_pred_btc.shape=}\")\n",
    "            print(f\"{loss=}\")\n",
    "\n",
    "            # Physical regularization: value of the retardation factor should decrease with increasing concentration\n",
    "            ret_inv_pred = self.retardation_inv_scaled(u_ret)\n",
    "            loss_phys = self.cfg.phys_mult * torch.mean(\n",
    "                torch.relu(ret_inv_pred[:-1] - ret_inv_pred[1:])\n",
    "            )\n",
    "            loss += loss_phys\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            c_pred_path = out_dir / f\"predicted_concentrations/c_pred_{epoch}.npy\"\n",
    "            c_pred_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            np.save(c_pred_path, ode_pred.detach().numpy())\n",
    "\n",
    "            return loss\n",
    "\n",
    "        # Iterate until maximum epoch number is reached\n",
    "        for _ in range(1, max_epochs + 1):\n",
    "            epoch += 1\n",
    "            dt = time.time()\n",
    "            optimizer.step(closure)\n",
    "            loss = closure()\n",
    "            dt = time.time() - dt\n",
    "\n",
    "            print(\n",
    "                f\"Training: Epoch [{epoch + 1}/{max_epochs}], \"\n",
    "                f\"Training Loss: {loss.item():.3e}, Runtime: {dt:.2f} secs\"\n",
    "            )\n",
    "\n",
    "            ret_pred_path = out_dir / f\"predicted_retardations/retPred_{epoch}.npy\"\n",
    "            ret_pred_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            np.save(ret_pred_path, self.retardation(u_ret).detach().numpy())\n",
    "            with open(out_dir / \"loss.txt\", \"a\") as f:\n",
    "                f.write(f\"{loss.item():.16f}\\n\")\n",
    "\n",
    "    def retardation_inv_scaled(self, u):\n",
    "        return self.dudt_fun.flux_modules[0].ret_inv_fun(u)\n",
    "\n",
    "    def retardation(self, u):\n",
    "        return (\n",
    "            1.0\n",
    "            / self.dudt_fun.flux_modules[0].ret_inv_fun(u)\n",
    "            / 10 ** self.dudt_fun.flux_modules[0].p_exp\n",
    "        )\n",
    "\n",
    "\n",
    "class ConcentrationChangeRatePredictor(nn.Module):\n",
    "    def __init__(self, u0, cfg, ret_inv_funs=None):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        Inputs:\n",
    "            u0      : initial condition, dim: [num_features, Nx]\n",
    "            cfg     : configuration object of the model setup, containing boundary condition types, values, learnable parameter settings, etc.\n",
    "        \"\"\"\n",
    "        if ret_inv_funs is None:\n",
    "            ret_inv_funs = [None] * len(u0)\n",
    "\n",
    "        super(ConcentrationChangeRatePredictor, self).__init__()\n",
    "\n",
    "        self.flux_modules = nn.ModuleList()\n",
    "        self.num_vars = u0.size(0)\n",
    "        self.cfg = cfg\n",
    "\n",
    "        # Create flux kernel for each variable to be calculated\n",
    "        for var_idx in range(self.num_vars):\n",
    "            self.flux_modules.append(\n",
    "                Flux_Kernels(\n",
    "                    u0[var_idx], self.cfg, var_idx, ret_inv_fun=ret_inv_funs[var_idx]\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def forward(self, t, u):\n",
    "        \"\"\"Computes du/dt to be put into the ODE solver\n",
    "\n",
    "        Args:\n",
    "            t (float): time point\n",
    "            u (tensor): the unknown variables to be calculated taken from the previous time step, dim: [num_features, Nx]\n",
    "\n",
    "        Returns:\n",
    "            tensor: the time derivative of u (du/dt), dim: [num_features, Nx]\n",
    "        \"\"\"\n",
    "        flux = []\n",
    "\n",
    "        # Use flux and state kernels to calculate du/dt for all unknown variables\n",
    "        for var_idx in range(self.num_vars):\n",
    "            # TODO: This is weird. Why is u_main the same as u_coupled?\n",
    "            flux.append(self.flux_modules[var_idx](u[[0]], u[[0]], t))\n",
    "\n",
    "        du = torch.stack(flux)\n",
    "\n",
    "        return du\n",
    "\n",
    "\n",
    "def plot_c_spaceseries(c, t_idx):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(c[t_idx, 0, :], label=\"diss\")\n",
    "    plt.plot(c[t_idx, 1, :], label=\"tot\")\n",
    "    plt.title(f\"Array at time step {t_idx}\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "def plot_c_timeseries(c, x_idx):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(c[:, 0, x_idx], label=\"diss\")\n",
    "    plt.plot(c[:, 1, x_idx], label=\"tot\")\n",
    "    plt.title(f\"c at x_idx = {x_idx}\")\n",
    "    plt.xlabel(\"Time step\")\n",
    "    plt.ylabel(\"c\")\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "def plot_c(t, x, c: np.ndarray):\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(18, 6))\n",
    "    pcolor_plot = ax1.pcolor(t, x, c[:, 0, :], cmap=\"viridis\")\n",
    "    plt.colorbar(pcolor_plot)\n",
    "    ax1.set_title(\"c_diss\")\n",
    "    ax1.set_xlabel(\"X index\")\n",
    "    ax1.set_ylabel(\"Time step\")\n",
    "\n",
    "    pcolor_plot = ax2.pcolor(t, x, c[:, 1, :], cmap=\"viridis\")\n",
    "    plt.colorbar(pcolor_plot)\n",
    "    ax2.set_title(\"c_tot\")\n",
    "    ax2.set_xlabel(\"X index\")\n",
    "    ax2.set_ylabel(\"Time step\")\n",
    "\n",
    "\n",
    "def pcolor_from_scatter(x, y, z, placeholder_value=0):\n",
    "    # Generate grid points from unique x and y values\n",
    "    unique_x = sorted(set(x))\n",
    "    unique_y = sorted(set(y))\n",
    "    X, Y = np.meshgrid(unique_x, unique_y)\n",
    "\n",
    "    # Create a dictionary to store z values based on (x, y) coordinates\n",
    "    z_dict = {(x_val, y_val): z_val for x_val, y_val, z_val in zip(x, y, z)}\n",
    "\n",
    "    # Create an array to store the z values for the pcolor plot\n",
    "    Z = np.zeros_like(X)\n",
    "\n",
    "    # Fill the Z array with actual and placeholder z values\n",
    "    for i, x_val in enumerate(unique_x):\n",
    "        for j, y_val in enumerate(unique_y):\n",
    "            Z[j, i] = z_dict.get((x_val, y_val), placeholder_value)\n",
    "\n",
    "    # Create the pcolor plot\n",
    "    plt.pcolor(X, Y, Z)\n",
    "    plt.colorbar()\n",
    "\n",
    "\n",
    "def iter_final_retardation_files(\n",
    "    root,\n",
    "    min_epoch: int = 100,\n",
    "    is_ret_OK: Optional[Callable[[np.ndarray], bool]] = None,\n",
    "    verbose: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Iterate trough a directory containing multiple\n",
    "    folders with FINN simulation results.\n",
    "    Return the path to the final ret curve file.\n",
    "    \"\"\"\n",
    "    finn_dirs = (p.parent for p in root.rglob(\"u_ret.npy\"))\n",
    "    for p in finn_dirs:\n",
    "        all_ret_file_paths = sorted(\n",
    "            (p / \"predicted_retardations\").glob(\"retPred_*.npy\"),\n",
    "            key=lambda x: int(x.stem.split(\"_\")[-1]),\n",
    "        )\n",
    "        if not all_ret_file_paths:\n",
    "            if verbose:\n",
    "                print(f\"Skipped {p} because no files found\")\n",
    "            continue\n",
    "\n",
    "        epoch = int(all_ret_file_paths[-1].stem.split(\"_\")[-1])\n",
    "        if epoch < min_epoch:\n",
    "            if verbose:\n",
    "                print(f\"Skipped {p} because epoch < {min_epoch}\")\n",
    "            continue\n",
    "\n",
    "        ret = np.load(all_ret_file_paths[-1])\n",
    "        if np.any(np.isnan(ret)):\n",
    "            if verbose:\n",
    "                print(f\"Skipped {p} because ret contains NaNs\")\n",
    "            continue\n",
    "\n",
    "        if np.any(np.isinf(ret)):\n",
    "            if verbose:\n",
    "                print(f\"Skipped {p} because ret contains infs\")\n",
    "            continue\n",
    "\n",
    "        if np.any(ret > 1e6) or np.any(ret < 1e-6):\n",
    "            if verbose:\n",
    "                print(f\"Skipped {p} because ret is not in [1e-6, 1e6]\")\n",
    "            continue\n",
    "\n",
    "        if is_ret_OK is not None:\n",
    "            if not is_ret_OK(ret):\n",
    "                if verbose:\n",
    "                    print(f\"Skipped {p} because ret is not OK\")\n",
    "                continue\n",
    "\n",
    "        yield p, all_ret_file_paths[-1]\n",
    "\n",
    "\n",
    "def is_below_curve(\n",
    "    curve_x: np.ndarray, curve_y: np.ndarray, points: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Checks whether a set of points is below a curve. The curve is a piecewise linear function given by points.\n",
    "\n",
    "    Args:\n",
    "        curve_x (np.ndarray): x-coordinates of the curve points\n",
    "        curve_y (np.ndarray): y-coordinates of the curve points\n",
    "        points (np.ndarray): (N, 2) array containing the points to check\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Boolean array indicating whether each point is below the curve.\n",
    "    \"\"\"\n",
    "    # Interpolate the curve using piecewise linear interpolation\n",
    "    interpolated_y = np.interp(points[:, 0], curve_x, curve_y)\n",
    "\n",
    "    # Compare the y-coordinates of the points with the interpolated y-values of the curve\n",
    "    below_curve = points[:, 1] < interpolated_y\n",
    "\n",
    "    return below_curve\n",
    "\n",
    "\n",
    "def is_above_curve(\n",
    "    curve_x: np.ndarray, curve_y: np.ndarray, points: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    interpolated_y = np.interp(points[:, 0], curve_x, curve_y)\n",
    "    below_curve = points[:, 1] > interpolated_y\n",
    "    return below_curve\n",
    "\n",
    "\n",
    "def random_fixed_length_seed():\n",
    "    return np.random.randint(10**8, 10**9 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "@dataclass\n",
    "class ExperimentalData:\n",
    "    t: np.ndarray\n",
    "    c_measured: np.ndarray\n",
    "\n",
    "\n",
    "def read_conf_dataframe(file_path) -> pd.DataFrame:\n",
    "    df = pd.read_excel(file_path, sheet_name=1, index_col=None, header=None).dropna(how=\"all\")\n",
    "    df.columns = [\"label\", \"value\", \"unit\"]\n",
    "    df = df.drop(columns=\"unit\").reset_index(drop=True)\n",
    "    df = df.T.reset_index(drop=True)\n",
    "    df.columns = df.iloc[0].tolist()\n",
    "    df = df.drop(0, axis=0).reset_index(drop=True).astype(float)\n",
    "    return df\n",
    "\n",
    "def read_experimental_data(file_path) -> pd.DataFrame:\n",
    "    df_measured = pd.read_excel(file_path, sheet_name=0, index_col=None, header=None).astype(float)\n",
    "    df_measured.columns = [\"t\", \"c\"]  # TODO: Which concentration?\n",
    "\n",
    "    df_simulated = pd.read_excel(file_path, sheet_name=2, index_col=None, header=None).astype(float)\n",
    "    df_simulated.columns = [\"t\", \"c\"]  # TODO: Which concentration?\n",
    "    \n",
    "    # assert np.array_equal(df_simulated[\"t\"], df_measured[\"t\"])\n",
    "    print(np.abs(df_simulated[\"t\"] - df_measured[\"t\"]).max())\n",
    "\n",
    "    df_conf = read_conf_dataframe(file_path)\n",
    "\n",
    "    conf = {k: v[0] for k,v in df_conf.to_dict().items()}\n",
    "    conf[\"Nx\"] = int(conf[\"Nx\"])\n",
    "    conf[\"Nt\"] = int(conf[\"Nt\"])\n",
    "    return conf, df_measured[\"t\"].to_numpy(), df_measured[\"c\"].to_numpy(), df_simulated[\"c\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_epochs': 100,\n",
      " 'output_dir': '../data_out/finn_experimental_data/data_core2',\n",
      " 'seed': 943765345,\n",
      " 'y_train_path': '../data/experimental_data/data_core2.xlsx'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pprint\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import params\n",
    "\n",
    "# data_core1:      c(x_end, t)\n",
    "# data_core2:      c(x_end, t)\n",
    "# data_core2_long: c(x, t_end)\n",
    "\n",
    "y_train_path = Path(\"../data/experimental_data/data_core2.xlsx\")\n",
    "output_dir = Path(f\"../data_out/finn_experimental_data/{y_train_path.stem}\")\n",
    "max_epochs = 100\n",
    "seed = 943765345\n",
    "cfg = params.Parameters.from_excel(str(y_train_path))\n",
    "\n",
    "\n",
    "input_dir = {\n",
    "    \"y_train_path\": str(y_train_path),\n",
    "    \"output_dir\": str(output_dir),\n",
    "    \"max_epochs\": max_epochs,\n",
    "    \"seed\": seed,\n",
    "}\n",
    "pprint.pprint(input_dir)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5711878726706345e-09\n"
     ]
    }
   ],
   "source": [
    "conf, t, c_measured, c_simulated = read_experimental_data(y_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'D': 2.0045664000000002e-05,\n",
       " 'por': 0.288,\n",
       " 'rho_s': 1957.0,\n",
       " 'X': 0.026034999999999996,\n",
       " 'T': 39.824440010000004,\n",
       " 'Nx': 20,\n",
       " 'Nt': 55,\n",
       " 'sample_radius': 0.02375,\n",
       " 'Q': 0.00010435199999999999,\n",
       " 'solubility': 1.6,\n",
       " 'Dirichlet': 0.0,\n",
       " 'Cauchy': 1.0}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_plot = np.linspace(0.01,2,100)\n",
    "ret_plot_model = AnalyticRetardation.freundlich(u_plot, por=cfg.por, rho_s=cfg.rho_s, Kf=cfg.Kf, nf=cfg.nf)\n",
    "plt.plot(u_plot, ret_plot_model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"/Users/r/Documents/dev/tmp/finn_repo_comparisions/timo_finn/python/diffusion_sorption/experimental_data/data/ret_phys_model_core2.npy\", ret_plot_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0790164699507967, 2.776701817854545)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_measured.std(), c_measured.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(t, np.log(c_measured+1e-9), label=\"Measured\")\n",
    "plt.plot(t, np.log(c_simulated+1e-9), label=\"Simulated\")\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"c\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "u0 = torch.zeros(cfg.num_vars, cfg.Nx, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConcentrationPredictor(\n",
    "    u0=u0,\n",
    "    cfg=cfg,\n",
    "    ret_inv_funs=[\n",
    "        create_mlp([1, 15, 15, 15, 1], nn.Tanh(), nn.Sigmoid()),\n",
    "        None,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "with open(output_dir / \"input.json\", \"w\") as f:\n",
    "    json.dump(input_dir, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train = torch.from_numpy(t)\n",
    "Y_train = torch.from_numpy(c_measured/160.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(2.5049, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(2.4113, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0583, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0490, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0471, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0455, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0442, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0431, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0423, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0415, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0410, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0405, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0401, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0398, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0395, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0393, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0392, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0390, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0389, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0388, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0387, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [2/100], Training Loss: 3.873e-02, Runtime: 33.91 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0387, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0387, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0386, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0386, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0385, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0385, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0385, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0384, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0384, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0384, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0384, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0384, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0384, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0384, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [3/100], Training Loss: 4.035e-02, Runtime: 25.66 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [4/100], Training Loss: 3.827e-02, Runtime: 25.29 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0382, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0382, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0382, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0382, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0382, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0382, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0382, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0382, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0382, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0394, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [5/100], Training Loss: 3.936e-02, Runtime: 24.99 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0394, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0392, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0391, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0389, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0388, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0387, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0386, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0385, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0384, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0384, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0382, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0382, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0382, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0381, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0381, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0380, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0380, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0380, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0379, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0379, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [6/100], Training Loss: 3.790e-02, Runtime: 23.71 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0379, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0379, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0382, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0382, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0381, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0381, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0381, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0381, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0381, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0381, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0381, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0381, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0379, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0379, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0379, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0379, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0379, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0379, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [7/100], Training Loss: 3.786e-02, Runtime: 23.97 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0379, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0379, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [8/100], Training Loss: 3.782e-02, Runtime: 24.09 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [9/100], Training Loss: 3.789e-02, Runtime: 23.70 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [10/100], Training Loss: 3.797e-02, Runtime: 24.75 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0407, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0402, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0397, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0393, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0390, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0386, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0385, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0382, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [11/100], Training Loss: 3.845e-02, Runtime: 23.68 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0382, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0381, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0380, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0380, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0379, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0379, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0379, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [12/100], Training Loss: 3.782e-02, Runtime: 24.06 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [13/100], Training Loss: 3.781e-02, Runtime: 24.20 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [14/100], Training Loss: 3.781e-02, Runtime: 24.44 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [15/100], Training Loss: 3.780e-02, Runtime: 23.97 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.0378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.4007, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [16/100], Training Loss: 6.232e-01, Runtime: 7.40 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [17/100], Training Loss: 6.232e-01, Runtime: 0.52 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [18/100], Training Loss: 6.232e-01, Runtime: 0.49 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [19/100], Training Loss: 6.232e-01, Runtime: 0.50 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [20/100], Training Loss: 6.232e-01, Runtime: 0.50 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [21/100], Training Loss: 6.232e-01, Runtime: 0.50 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [22/100], Training Loss: 6.232e-01, Runtime: 0.51 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [23/100], Training Loss: 6.232e-01, Runtime: 0.60 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [24/100], Training Loss: 6.232e-01, Runtime: 0.52 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [25/100], Training Loss: 6.232e-01, Runtime: 0.49 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [26/100], Training Loss: 6.232e-01, Runtime: 0.48 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [27/100], Training Loss: 6.232e-01, Runtime: 0.48 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [28/100], Training Loss: 6.232e-01, Runtime: 0.48 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [29/100], Training Loss: 6.232e-01, Runtime: 0.49 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [30/100], Training Loss: 6.232e-01, Runtime: 0.48 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [31/100], Training Loss: 6.232e-01, Runtime: 0.49 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [32/100], Training Loss: 6.232e-01, Runtime: 0.57 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [33/100], Training Loss: 6.232e-01, Runtime: 0.48 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [34/100], Training Loss: 6.232e-01, Runtime: 0.49 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [35/100], Training Loss: 6.232e-01, Runtime: 0.49 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [36/100], Training Loss: 6.232e-01, Runtime: 0.49 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [37/100], Training Loss: 6.232e-01, Runtime: 0.48 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [38/100], Training Loss: 6.232e-01, Runtime: 0.48 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [39/100], Training Loss: 6.232e-01, Runtime: 0.48 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [40/100], Training Loss: 6.232e-01, Runtime: 0.48 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [41/100], Training Loss: 6.232e-01, Runtime: 0.58 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [42/100], Training Loss: 6.232e-01, Runtime: 0.48 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [43/100], Training Loss: 6.232e-01, Runtime: 0.48 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [44/100], Training Loss: 6.232e-01, Runtime: 0.50 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [45/100], Training Loss: 6.232e-01, Runtime: 0.52 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [46/100], Training Loss: 6.232e-01, Runtime: 0.51 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [47/100], Training Loss: 6.232e-01, Runtime: 0.51 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [48/100], Training Loss: 6.232e-01, Runtime: 0.51 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [49/100], Training Loss: 6.232e-01, Runtime: 0.52 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [50/100], Training Loss: 6.232e-01, Runtime: 0.52 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [51/100], Training Loss: 6.232e-01, Runtime: 0.52 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [52/100], Training Loss: 6.232e-01, Runtime: 0.62 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [53/100], Training Loss: 6.232e-01, Runtime: 0.50 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [54/100], Training Loss: 6.232e-01, Runtime: 0.49 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [55/100], Training Loss: 6.232e-01, Runtime: 0.50 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [56/100], Training Loss: 6.232e-01, Runtime: 0.49 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [57/100], Training Loss: 6.232e-01, Runtime: 0.49 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [58/100], Training Loss: 6.232e-01, Runtime: 0.48 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [59/100], Training Loss: 6.232e-01, Runtime: 0.48 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [60/100], Training Loss: 6.232e-01, Runtime: 0.50 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [61/100], Training Loss: 6.232e-01, Runtime: 0.64 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [62/100], Training Loss: 6.232e-01, Runtime: 0.50 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [63/100], Training Loss: 6.232e-01, Runtime: 0.49 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [64/100], Training Loss: 6.232e-01, Runtime: 0.48 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [65/100], Training Loss: 6.232e-01, Runtime: 0.50 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [66/100], Training Loss: 6.232e-01, Runtime: 0.49 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [67/100], Training Loss: 6.232e-01, Runtime: 0.50 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [68/100], Training Loss: 6.232e-01, Runtime: 0.49 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [69/100], Training Loss: 6.232e-01, Runtime: 0.49 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [70/100], Training Loss: 6.232e-01, Runtime: 0.58 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [71/100], Training Loss: 6.232e-01, Runtime: 0.49 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [72/100], Training Loss: 6.232e-01, Runtime: 0.49 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [73/100], Training Loss: 6.232e-01, Runtime: 0.49 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [74/100], Training Loss: 6.232e-01, Runtime: 0.50 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [75/100], Training Loss: 6.232e-01, Runtime: 0.49 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [76/100], Training Loss: 6.232e-01, Runtime: 0.50 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [77/100], Training Loss: 6.232e-01, Runtime: 0.50 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [78/100], Training Loss: 6.232e-01, Runtime: 0.50 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [79/100], Training Loss: 6.232e-01, Runtime: 0.57 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [80/100], Training Loss: 6.232e-01, Runtime: 0.49 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [81/100], Training Loss: 6.232e-01, Runtime: 0.50 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [82/100], Training Loss: 6.232e-01, Runtime: 0.50 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [83/100], Training Loss: 6.232e-01, Runtime: 0.50 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [84/100], Training Loss: 6.232e-01, Runtime: 0.49 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [85/100], Training Loss: 6.232e-01, Runtime: 0.50 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [86/100], Training Loss: 6.232e-01, Runtime: 0.49 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [87/100], Training Loss: 6.232e-01, Runtime: 0.49 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [88/100], Training Loss: 6.232e-01, Runtime: 0.49 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [89/100], Training Loss: 6.232e-01, Runtime: 0.50 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [90/100], Training Loss: 6.232e-01, Runtime: 0.58 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [91/100], Training Loss: 6.232e-01, Runtime: 0.49 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [92/100], Training Loss: 6.232e-01, Runtime: 0.49 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [93/100], Training Loss: 6.232e-01, Runtime: 0.50 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [94/100], Training Loss: 6.232e-01, Runtime: 0.49 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [95/100], Training Loss: 6.232e-01, Runtime: 0.49 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [96/100], Training Loss: 6.232e-01, Runtime: 0.50 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [97/100], Training Loss: 6.232e-01, Runtime: 0.49 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [98/100], Training Loss: 6.232e-01, Runtime: 0.49 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [99/100], Training Loss: 6.232e-01, Runtime: 0.58 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [100/100], Training Loss: 6.232e-01, Runtime: 0.49 secs\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "u_train.shape=torch.Size([55])\n",
      "ode_pred_btc.shape=torch.Size([55])\n",
      "loss=tensor(0.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Training: Epoch [101/100], Training Loss: 6.232e-01, Runtime: 0.50 secs\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.run_training(\n",
    "    t=t_train,\n",
    "    u_train=Y_train,\n",
    "    out_dir=output_dir,\n",
    "    max_epochs=max_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "t must be a torch.Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 3\u001b[0m     c_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m np\u001b[38;5;241m.\u001b[39msave(output_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc_full_predictions.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m, c_predictions\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m      5\u001b[0m np\u001b[38;5;241m.\u001b[39msave(output_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc_train_predictions.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m, c_predictions\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/.venvs/p3inn/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venvs/p3inn/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[108], line 378\u001b[0m, in \u001b[0;36mConcentrationPredictor.forward\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, t):\n\u001b[1;32m    369\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict the concentration profile at given time steps from an initial condition using the FINN method.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m        tensor: Full field solution of concentration at given time steps.\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43modeint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdudt_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mu0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdopri8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venvs/p3inn/lib/python3.11/site-packages/torchdiffeq/_impl/odeint.py:72\u001b[0m, in \u001b[0;36modeint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21modeint\u001b[39m(func, y0, t, \u001b[38;5;241m*\u001b[39m, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-7\u001b[39m, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-9\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, event_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     32\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Integrate a system of ordinary differential equations.\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m    Solves the initial value problem for a non-stiff system of first order ODEs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m        ValueError: if an invalid `method` is provided.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m     shapes, func, y0, t, rtol, atol, method, options, event_fn, t_is_reversed \u001b[38;5;241m=\u001b[39m \u001b[43m_check_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSOLVERS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     solver \u001b[38;5;241m=\u001b[39m SOLVERS[method](func\u001b[38;5;241m=\u001b[39mfunc, y0\u001b[38;5;241m=\u001b[39my0, rtol\u001b[38;5;241m=\u001b[39mrtol, atol\u001b[38;5;241m=\u001b[39matol, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.venvs/p3inn/lib/python3.11/site-packages/torchdiffeq/_impl/misc.py:258\u001b[0m, in \u001b[0;36m_check_inputs\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn, SOLVERS)\u001b[0m\n\u001b[1;32m    255\u001b[0m         options[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m _rms_norm\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# Normalise time\u001b[39;00m\n\u001b[0;32m--> 258\u001b[0m \u001b[43m_check_timelike\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m t_is_reversed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(t) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m t[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m t[\u001b[38;5;241m1\u001b[39m]:\n",
      "File \u001b[0;32m~/.venvs/p3inn/lib/python3.11/site-packages/torchdiffeq/_impl/misc.py:335\u001b[0m, in \u001b[0;36m_check_timelike\u001b[0;34m(name, timelike, can_grad)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_timelike\u001b[39m(name, timelike, can_grad):\n\u001b[0;32m--> 335\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(timelike, torch\u001b[38;5;241m.\u001b[39mTensor), \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m must be a torch.Tensor\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name)\n\u001b[1;32m    336\u001b[0m     _assert_floating(name, timelike)\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m timelike\u001b[38;5;241m.\u001b[39mndimension() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m must be one dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name)\n",
      "\u001b[0;31mAssertionError\u001b[0m: t must be a torch.Tensor"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    c_predictions = model(t)\n",
    "np.save(output_dir / \"c_full_predictions.npy\", c_predictions.detach().numpy())\n",
    "np.save(output_dir / \"c_train_predictions.npy\", c_predictions.detach().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p3inn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
