{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import keras_tuner\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data from .npy files\n",
    "x = np.load(\"../data_out/p3inn/core2/x_data.npy\")\n",
    "y = np.load(\"../data_out/p3inn/core2/y_data.npy\")\n",
    "\n",
    "# Reshape x if it's 1D to ensure it's a column vector\n",
    "if x.ndim == 1:\n",
    "    x = x.reshape(-1, 1)\n",
    "\n",
    "x_train = x.copy()\n",
    "y_train = y.copy()\n",
    "\n",
    "# Normalize data\n",
    "scaler_x = MinMaxScaler()\n",
    "x_train = scaler_x.fit_transform(x_train)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_train = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "\n",
    "del scaler_x\n",
    "del scaler_y\n",
    "\n",
    "plt.plot(x_train, y_train, \".\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from ../data_out/hypertuning/p3inn_core2/hyperband#tanh:lr_optimizer_schedule/tuner0.json\n",
      "None\n",
      "Search space summary\n",
      "Default search space size: 10\n",
      "n_hidden1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 256, 'step': 16, 'sampling': 'linear'}\n",
      "extra_hidden (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "initial_learning_rate (Float)\n",
      "{'default': 0.005, 'conditions': [], 'min_value': 0.005, 'max_value': 0.1, 'step': None, 'sampling': 'log'}\n",
      "scheduler (Choice)\n",
      "{'default': 'cosine', 'conditions': [], 'values': ['cosine', 'expo'], 'ordered': False}\n",
      "first_decay_steps (Choice)\n",
      "{'default': 30, 'conditions': [], 'values': [30, 100], 'ordered': True}\n",
      "optimizer (Choice)\n",
      "{'default': 'adamw', 'conditions': [], 'values': ['adamw', 'adam'], 'ordered': False}\n",
      "batch_size (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 8, 'max_value': 64, 'step': 8, 'sampling': 'linear'}\n",
      "decay_steps (Choice)\n",
      "{'default': 10, 'conditions': [], 'values': [10, 60], 'ordered': True}\n",
      "decay_rate (Choice)\n",
      "{'default': 0.98, 'conditions': [], 'values': [0.98, 0.8], 'ordered': True}\n",
      "n_hidden2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 256, 'step': 16, 'sampling': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "class MyHyperModel(keras_tuner.HyperModel):\n",
    "    def build(self, hp: keras_tuner.HyperParameters):\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=(1,)),\n",
    "                # keras.layers.BatchNormalization(),\n",
    "                keras.layers.Dense(hp.Int(\"n_hidden1\", 16, 256, 16), activation=\"tanh\"),\n",
    "                \n",
    "            ]\n",
    "        )\n",
    "        if hp.Boolean(\"extra_hidden\", False):\n",
    "            model.add(\n",
    "                keras.layers.Dense(hp.Int(\"n_hidden2\", 16, 256, 16), activation=\"tanh\")\n",
    "            )\n",
    "        model.add(\n",
    "            keras.layers.Dense(1)\n",
    "        )\n",
    "\n",
    "        # good adam values: 0.06 (min: 0.02, max: 0.1)\n",
    "        initial_learning_rate = hp.Float(\n",
    "            \"initial_learning_rate\", min_value=0.005, max_value=0.1, sampling=\"log\"\n",
    "        )\n",
    "        scheduler = hp.Choice(\"scheduler\", [\"cosine\", \"expo\"])\n",
    "        if scheduler == \"cosine\":\n",
    "            learning_rate = keras.optimizers.schedules.CosineDecayRestarts(\n",
    "                initial_learning_rate,\n",
    "                first_decay_steps=hp.Choice(\"first_decay_steps\", [30, 100]),\n",
    "            )\n",
    "        elif scheduler == \"expo\":\n",
    "            learning_rate = keras.optimizers.schedules.ExponentialDecay(\n",
    "                initial_learning_rate,\n",
    "                decay_steps=hp.Choice(\"decay_steps\", [10, 60]),\n",
    "                decay_rate=hp.Choice(\"decay_rate\", [0.98, 0.8]),\n",
    "                staircase=True,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown schedule: {scheduler}\")\n",
    "        # learning_rate = initial_learning_rate\n",
    "\n",
    "        optimizer_choice = hp.Choice(\"optimizer\", [\"adamw\", \"adam\"])\n",
    "        if optimizer_choice == \"adam\":\n",
    "            optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        elif optimizer_choice == \"adamw\":\n",
    "            optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown optimizer: {optimizer_choice}\")\n",
    "\n",
    "        model.compile(optimizer=optimizer, loss=\"mse\")\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        return model.fit(\n",
    "            *args,\n",
    "            batch_size=hp.Int('batch_size', min_value=8, max_value=64, step=8),\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "# tuner = keras_tuner.RandomSearch(\n",
    "#     MyHyperModel(),\n",
    "#     objective=\"loss\",\n",
    "#     max_trials=100,  # Number of hyperparameter combinations to try\n",
    "#     executions_per_trial=1,  # Increase if you want to average multiple runs per trial\n",
    "#     directory=\"../data_out/hypertuning/p3inn_core2\",  # Where to save tuning results\n",
    "#     project_name=\"relu:lr_optimizer_schedule\",\n",
    "#     # overwrite=True,\n",
    "# )\n",
    "tuner = keras_tuner.Hyperband(\n",
    "    MyHyperModel(),\n",
    "    objective=\"loss\",\n",
    "    max_epochs=500,\n",
    "    factor=3,\n",
    "    hyperband_iterations=3,\n",
    "    executions_per_trial=4,  # Increase if you want to average multiple runs per trial\n",
    "    directory=\"../data_out/hypertuning/p3inn_core2\",  # Where to save tuning results\n",
    "    project_name=\"hyperband#tanh:lr_optimizer_schedule\",\n",
    "    # overwrite=True,\n",
    ")\n",
    "print(tuner.remaining_trials)\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.088826\t16\tadamw\t0\t0.007814\n",
    "\n",
    "# best loss so far: 0.005 (with adam, lr=0.06)\n",
    "# but I need at least 0.001\n",
    "# so min_delta of     0.0001 seems good\n",
    "EARLY_STOPPING_PARAMS = dict(monitor=\"loss\", patience=150, min_delta=0.0001)\n",
    "TRAINING_PARAMS = dict(\n",
    "    # epochs=1000,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    **TRAINING_PARAMS,\n",
    "    callbacks=[keras.callbacks.EarlyStopping(**EARLY_STOPPING_PARAMS)],\n",
    ")\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0]# 575 trials before bed (best loss=0.00193)\n",
    "!say \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for good_hp in tuner.get_best_hyperparameters(num_trials=10):\n",
    "    print(good_hp.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tuner.get_best_hyperparameters(1)[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hyperparameters.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the best model\n",
    "history = best_model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    **TRAINING_PARAMS,\n",
    "    callbacks=[keras.callbacks.EarlyStopping(**EARLY_STOPPING_PARAMS)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 6))\n",
    "\n",
    "ax1.semilogy(history.history[\"loss\"], label=\"Training Loss\")\n",
    "ax1.semilogy(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "# Plot learned function and data\n",
    "x_plot = np.linspace(x_train.min(), x_train.max(), 200).reshape(\n",
    "    -1, 1\n",
    ")  # 200 points for smooth curve\n",
    "\n",
    "# x_plot_scaled = scaler_x.transform(x_plot)  # Scale the x values for prediction\n",
    "# y_pred_scaled = best_model.predict(x_plot_scaled)\n",
    "# y_pred = scaler_y.inverse_transform(\n",
    "#     y_pred_scaled\n",
    "# ).flatten()  # Inverse scale predictions\n",
    "\n",
    "x_plot_scaled = x_plot\n",
    "y_pred = best_model.predict(x_plot_scaled)\n",
    "\n",
    "\n",
    "ax2.scatter(x_train, y_train, label=\"Data\")\n",
    "ax2.plot(x_plot, y_pred, color=\"red\", label=\"Learned Function\")\n",
    "ax2.set_xlabel(\"x\")\n",
    "ax2.set_ylabel(\"y\")\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "results = []\n",
    "for trial in tuner.oracle.get_best_trials(100):\n",
    "    hps = trial.hyperparameters.values\n",
    "    hps['score'] = trial.score\n",
    "    results.append(hps)\n",
    "df = pd.DataFrame(results).sort_values(by=\"score\", ignore_index=True)\n",
    "\n",
    "categories = [\"optimizer\", \"scheduler\"]\n",
    "for cat in categories:\n",
    "    df[f\"#{cat}\"] = df[cat].astype(\"category\").cat.codes\n",
    "\n",
    "# Reorder columns to place 'score' last and categories before it\n",
    "other_cols = [col for col in df.columns if col not in categories and col != 'score' and col not in [f\"#{cat}\" for cat in categories]]\n",
    "ordered_cols = other_cols + categories + [f\"#{cat}\" for cat in categories] + ['score']\n",
    "df = df[ordered_cols]\n",
    "\n",
    "# df = df.query(\"optimizer == 'adam'\").drop(\"#optimizer\", axis=1).reset_index(drop=True)\n",
    "df = df.query(\"scheduler == 'cosine'\").drop(\"#scheduler\", axis=1).reset_index(drop=True)\n",
    "display(df)\n",
    "\n",
    "fig = px.parallel_coordinates(df, color=\"score\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p3inn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
