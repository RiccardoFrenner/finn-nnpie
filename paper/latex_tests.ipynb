{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've laid out the standard regression setting. Let's proceed to the Bayesian perspective.\n",
    "\n",
    "**Bayesian Neural Network (BNN)**\n",
    "\n",
    "Instead of point estimates for the parameters of $f$, a BNN places prior distributions over them.  Let's denote the weights and biases of the neural network by $w$.\n",
    "\n",
    "* **Prior:**  $p(w)$  (e.g.,  $w_j \\sim \\mathcal{N}(0, \\sigma_w^2)$ for each weight $w_j$)\n",
    "\n",
    "* **Likelihood:** $p(D | w)$. Assuming independent noise, this decomposes as:\n",
    "    $$p(D|w) = \\prod_{i=1}^n p(D_i|w) = \\prod_{i=1}^n p(f(x_i; w) + \\epsilon_i | w)$$\n",
    "    With your normal noise assumption:\n",
    "    $$p(D|w) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(D_i - f(x_i; w))^2}{2\\sigma^2}\\right)$$\n",
    "\n",
    "* **Posterior:** $p(w | D)$. This is our goal, representing the updated belief about the weights after observing the data. Bayes' theorem gives:\n",
    "    $$p(w | D) = \\frac{p(D|w) p(w)}{p(D)}$$\n",
    "    where $p(D) = \\int p(D|w) p(w) \\, dw$ is the marginal likelihood (evidence).\n",
    "\n",
    "Since the posterior is typically intractable for BNNs (due to the non-linearity of $f$), we resort to approximations.\n",
    "\n",
    "**Approximation Methods (briefly, as requested):**\n",
    "\n",
    "* **Variational Inference:** Approximate the posterior $p(w|D)$ with a simpler distribution $q(w|\\theta)$ parameterized by $\\theta$. Minimize the Kullback-Leibler divergence $KL[q(w|\\theta) || p(w|D)]$.\n",
    "\n",
    "* **Markov Chain Monte Carlo (MCMC):** Construct a Markov chain whose stationary distribution is the posterior $p(w|D)$. Sample from this chain to obtain samples representing the posterior.\n",
    "\n",
    "* **Laplace Approximation:**  Approximate the posterior with a Gaussian centered at the maximum a posteriori (MAP) estimate.\n",
    "\n",
    "This provides the core mathematical framework.  Further details on specific approximation methods can be provided if needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's formalize this. You have a deterministic solver $S(h, D)$ that produces weights $w$ given hyperparameters $h$ and training data $D$. You also have a prior distribution over hyperparameters $p(h)$. Your neural network is a function $f(x; w)$ that maps inputs $x$ to outputs $y$ given weights $w$.\n",
    "\n",
    "You want to find $p(y | x, D)$, which can be written as:\n",
    "\n",
    "$$ p(y | x, D) = \\int p(y, h | x, D) \\, dh = \\int p(y | x, h, D) p(h | x, D) \\, dh $$\n",
    "\n",
    "Since $x$ is independent of $h$ given $D$ (the hyperparameters are chosen based on the data, not the specific input $x$), we have $p(h|x,D) = p(h|D)$.  Further, since $w = S(h,D)$ is deterministic, $y$ is deterministic given $x$, $h$ and $D$. We can write this as $y = f(x; S(h,D))$.  Therefore, $p(y | x, h, D)$ is a Dirac delta function:\n",
    "\n",
    "$$ p(y | x, h, D) = \\delta(y - f(x; S(h,D))) $$\n",
    "\n",
    "Substituting this into the integral, we get:\n",
    "\n",
    "$$ p(y | x, D) = \\int \\delta(y - f(x; S(h,D))) p(h|D) \\, dh $$\n",
    "\n",
    "Now, the tricky part is $p(h|D)$, the posterior distribution of hyperparameters given the data.  This is generally intractable to compute directly.  However, we can relate it to the prior $p(h)$ and the likelihood $p(D|h)$ using Bayes' theorem:\n",
    "\n",
    "$$ p(h|D) = \\frac{p(D|h) p(h)}{p(D)} $$\n",
    "\n",
    "where $p(D) = \\int p(D|h) p(h) \\, dh$ is the evidence.  The likelihood $p(D|h)$ is also complex to compute as it involves marginalizing over all possible weights $w$ that could be generated by the solver $S(h,D)$.\n",
    "\n",
    "Thus, the full expression becomes:\n",
    "\n",
    "$$ p(y | x, D) = \\frac{1}{p(D)} \\int \\delta(y - f(x; S(h,D))) p(D|h) p(h) \\, dh $$\n",
    "\n",
    "This integral is generally intractable.  A practical approach would be to approximate the posterior $p(h|D)$.  One way is to sample from $p(h)$ and then use importance sampling to re-weight the samples according to $p(D|h)$.  Alternatively, you could use variational inference to approximate $p(h|D)$ with a more tractable distribution.\n",
    "\n",
    "Another simplification, if you're just interested in sampling from $p(y | x, D)$, is to sample $h$ from $p(h)$, compute $w = S(h,D)$, and then compute $y = f(x; w)$.  This gives you samples from the joint distribution $p(y,h | x,D)$, and thus marginally from $p(y | x,D)$. This bypasses the need to compute $p(h|D)$ directly.  This is equivalent to implicitly using $p(h)$ as an approximation of $p(h|D)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down why sampling $h \\sim p(h)$ and then computing $y = f(x; S(h, D))$ gives you samples from $p(y, h | x, D)$, and consequently, $p(y | x, D)$.\n",
    "\n",
    "1. **Sampling from the Prior:** You start by sampling $h$ from your prior distribution $p(h)$.  This means the values of $h$ you obtain are representative of your initial beliefs about the hyperparameters, before considering the data.\n",
    "\n",
    "2. **Deterministic Computation of $w$ and $y$:**  Given a specific $h$ and the data $D$, the solver $S(h, D)$ deterministically produces the weights $w$. Subsequently, the neural network $f(x; w)$ deterministically produces the output $y$ for a given input $x$.\n",
    "\n",
    "3. **Joint Distribution:** Because $w$ and $y$ are deterministic functions of $h$ and $D$, sampling $h$ from $p(h)$ and then computing $y$ is equivalent to sampling from the joint distribution $p(y, h | x, D)$.  Think of it this way: for every $h$ drawn from $p(h)$, you're getting a corresponding $y$.  The frequency with which different $(h, y)$ pairs appear will be proportional to $p(h)$, and implicitly also reflects the complex relationship between $h$ and $y$ through $S(h,D)$ and $f(x; w)$.  We can also write it explicitly:\n",
    "   $p(y,h|x,D) = p(y|h,x,D) p(h|x,D)$. As discussed before, $p(h|x,D) = p(h|D)$, and with enough data, we might approximate $p(h|D) \\approx p(h)$. Also, $p(y|h,x,D) = \\delta(y-f(x;S(h,D)))$. Substituting this yields: $p(y,h|x,D) \\approx \\delta(y-f(x;S(h,D))) p(h)$. This shows, how by sampling $h$ from $p(h)$ and applying the deterministic functions $S$ and $f$ you are effectively sampling from an approximation to $p(y,h|x,D)$.\n",
    "\n",
    "\n",
    "4. **Marginal Distribution:**  If you have samples from a joint distribution $p(y, h | x, D)$, you automatically have samples from the marginal distribution $p(y | x, D)$.  To see why, consider a large number of $(h, y)$ samples.  If you ignore the $h$ values and only look at the $y$ values, these $y$ values will be distributed according to $p(y | x, D)$.  Formally, the marginal distribution is obtained by integrating the joint distribution over all possible values of $h$:\n",
    "    $$ p(y | x, D) = \\int p(y, h | x, D) \\, dh $$\n",
    "    By sampling from the joint distribution and then discarding the $h$ values, you are effectively performing this integration numerically.\n",
    "\n",
    "\n",
    "In summary, the procedure creates samples that reflect how likely different $y$ values are, given your prior beliefs about the hyperparameters and the deterministic mapping from hyperparameters to network outputs. This gives you a practical way to explore the distribution of possible outputs, even though calculating $p(y | x, D)$ directly is usually intractable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution to sample from p(y | x, D)\n",
    "- sample from $p(h | D)$ and compute $y=f(x; S(D,h))$\n",
    "- sample from $p(h | D)$ using importance sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importance sampling is a technique for estimating properties of a distribution, such as expectations, when sampling directly from that distribution is difficult.  Here's how to apply it to sample from the posterior $p(h|D)$, and then ultimately the posterior predictive $p(y|x,D)$, recognizing the challenges:\n",
    "\n",
    "**1. Choose a Proposal Distribution $q(h)$:**\n",
    "\n",
    "You need a proposal distribution $q(h)$ that is easy to sample from and that has support everywhere $p(h|D)$ has support (meaning $q(h) > 0$ wherever $p(h|D) > 0$).  Common choices include:\n",
    "\n",
    "* **Gaussian distribution:**  Often centered around the maximum a posteriori (MAP) estimate of $h$.\n",
    "* **Uniform distribution:**  Over a region that contains most of the probability mass of $p(h|D)$.\n",
    "* **A more sophisticated distribution** tailored to your specific problem.\n",
    "\n",
    "**2. Calculate the Importance Weights:**\n",
    "\n",
    "For each sample $h_i$ drawn from $q(h)$, calculate the importance weight:\n",
    "\n",
    "$$ w_i = \\frac{p(h_i|D)}{q(h_i)} = \\frac{p(D|h_i)p(h_i)}{p(D)q(h_i)} \\propto \\frac{p(D|h_i)p(h_i)}{q(h_i)} $$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $p(D|h_i)$ is the likelihood of the data given the parameters $h_i$.\n",
    "* $p(h_i)$ is the prior distribution over the parameters.\n",
    "* $p(D)$ is the evidence (marginal likelihood), which is often difficult to compute.  However, since it's a constant with respect to $h$, we can often ignore it and work with unnormalized weights.  We'll then normalize the weights later.\n",
    "\n",
    "**3. Normalize the Weights:**\n",
    "\n",
    "$$ \\tilde{w}_i = \\frac{w_i}{\\sum_{j=1}^N w_j} $$\n",
    "\n",
    "where $N$ is the number of samples.\n",
    "\n",
    "**4.  Approximate Expectations:**\n",
    "\n",
    "You can now approximate expectations of functions of $h$ with respect to the posterior:\n",
    "\n",
    "$$ E_{p(h|D)}[g(h)] \\approx \\sum_{i=1}^N \\tilde{w}_i g(h_i) $$\n",
    "\n",
    "**5. Sampling from the Posterior Predictive:**\n",
    "\n",
    "To get samples from $p(y|x,D) = \\int \\delta(y - f(x;S(h,D)))p(h|D) dh$:\n",
    "1. Draw $h_i$ from the proposal distribution $q(h)$.\n",
    "2. Compute $w_i$ and $\\tilde{w}_i$ as described in steps 2 and 3.\n",
    "3. Sample from $p(y | x, h_i)$ (if $S(h,D)=h$), where the sample is weighted by $\\tilde{w}_i$. Since we are using a delta function here, we just compute $y_i = f(x; S(h_i, D))$ and consider it a sample of the posterior predictive *weighted by $\\tilde{w}_i$*.\n",
    "\n",
    "In practice, $y_i$ could be easily obtained since we are usually working with deterministic models.\n",
    "\n",
    "If $f$ is stochastic, we could approximate the expectation over $y$ given $x$ by: $E_{p(y|x,D)} \\approx \\sum_{i=1}^N \\tilde{w}_i f(x;S(h_i,D))$\n",
    "\n",
    "**Challenges with Importance Sampling for Posterior Distributions:**\n",
    "\n",
    "* **Curse of Dimensionality:** As the dimensionality of $h$ increases, it becomes increasingly difficult to find a good proposal distribution $q(h)$ that adequately covers the important regions of $p(h|D)$. This can lead to very large weights for a small proportion of the samples, negating the benefit.\n",
    "* **Choosing a Good Proposal Distribution:**  The effectiveness of importance sampling hinges critically on the choice of $q(h)$.  A poor choice can lead to highly variable estimates and slow convergence.\n",
    "\n",
    "**Alternatives and Improvements:**\n",
    "\n",
    "If importance sampling proves problematic, consider these alternatives:\n",
    "\n",
    "* **Markov Chain Monte Carlo (MCMC):**  MCMC methods are often preferred for high-dimensional posteriors.\n",
    "* **Sequential Monte Carlo (SMC):**  SMC methods can be more robust than standard importance sampling, especially in complex scenarios.\n",
    "* **Adaptive Importance Sampling:**  These methods try to iteratively improve the proposal distribution during the sampling process.\n",
    "\n",
    "\n",
    "If you can provide more details about your specific problem (e.g., the form of your likelihood and prior), I can give more specific advice on choosing a suitable approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
